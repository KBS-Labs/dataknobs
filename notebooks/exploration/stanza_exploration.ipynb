{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b0fba6",
   "metadata": {},
   "source": [
    "# Stanford NLP Stanza Exploration\n",
    "\n",
    "## Prerequisite setup\n",
    "\n",
    "### Add dependency for \"stanza\" package:\n",
    "\n",
    "```sh\n",
    "% poetry add stanza\n",
    "```\n",
    "\n",
    "### Download stanza resources:\n",
    "\n",
    "```nb\n",
    "import stanza\n",
    "stanza.download('en', model_dir='/data/opt/stanza_resources')\n",
    "```\n",
    "\n",
    "### (Optional) Start CoreNLP server:\n",
    "\n",
    "To take advantage of extra functionality, e.g., coreference resolution, etc,\n",
    "start the CoreNLP server (from outside this notebook's environment/container.)\n",
    "\n",
    "```sh\n",
    "% bin/start_corenlp.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9643a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebooks.util.nbloader\n",
    "import notebooks.nb.utils as nb_utils\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from datetime import datetime\n",
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "import dataknobs.utils.pandas_utils as pd_utils\n",
    "import dataknobs.utils.stanza_utils as stanza_utils\n",
    "import notebooks.util.widget_utils as widget_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d0638",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a67b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "## Derived environmental initializations\n",
    "##\n",
    "## NOTE: Double-check this cell's output in case the auto-derivation fails\n",
    "##       and you will rely on one of these variables.\n",
    "##\n",
    "\n",
    "CORENLP_IP = nb_utils.get_subnet_ip('corenlp', verbose=True)\n",
    "\n",
    "if CORENLP_IP is None:\n",
    "    print(f'***WARNING: CoreNLP server is not up.')\n",
    "\n",
    "##\n",
    "## Global notebook variables\n",
    "##\n",
    "\n",
    "cur_text = ''    # Latest text input\n",
    "ann = None       # CoreNLP annotations\n",
    "doc = None       # Stanza document\n",
    "doc_df = None    # Stanza document DataFrame\n",
    "en_nlp = None    # Stanza english NLP\n",
    "coref_data = None\n",
    "parse_data = None\n",
    "stanza_doc_path = ''\n",
    "corenlp_ann_path = ''\n",
    "corenlp_results = None\n",
    "stanza_processors = list(stanza_utils.STANZA_PROCESSORS)\n",
    "corenlp_annotators = list(stanza_utils.CORENLP_ANNOTATORS)\n",
    "cur_max_rows = 100\n",
    "\n",
    "proc_checkboxes = widget_utils.MultiCheckbox(\n",
    "    list(stanza_utils.STANZA_PROCESSORS),\n",
    "    stanza_processors,\n",
    ")\n",
    "\n",
    "annotator_checkboxes = widget_utils.MultiCheckbox(\n",
    "    list(stanza_utils.CORENLP_ANNOTATORS),\n",
    "    stanza_processors,\n",
    "    num_cols=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4febb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03aaae38",
   "metadata": {},
   "source": [
    "## Stanza Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596120f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(proc_checkboxes.ui)\n",
    "\n",
    "@interact_manual\n",
    "def stanza_exploration(\n",
    "    text=cur_text,\n",
    "):\n",
    "    global cur_text, stanza_processors, en_nlp, doc, doc_df\n",
    "    cur_text = text\n",
    "    changed = (stanza_processors != proc_checkboxes.selected)\n",
    "    stanza_processors = proc_checkboxes.selected\n",
    "    if en_nlp is None or changed:\n",
    "        en_nlp = stanza.Pipeline(\n",
    "            'en',\n",
    "            model_dir=stanza_utils.STANZA_RESOURCES_DIR,\n",
    "            processors=stanza_processors,\n",
    "            download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n",
    "        )\n",
    "    doc = en_nlp(text)\n",
    "    doc_df = stanza_utils.doc2df(doc)\n",
    "    print(f'Stanza document for \"{text}\":')\n",
    "    \n",
    "    @interact\n",
    "    def show_dataframe(max_rows=widgets.IntText(cur_max_rows)):\n",
    "        global cur_max_rows\n",
    "        cur_max_rows = max_rows\n",
    "        nb_utils.display_df(doc_df, max_rows=max_rows, max_cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4840a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e83012ca",
   "metadata": {},
   "source": [
    "## CoreNLP Exploration\n",
    "\n",
    "### (If the CoreNLP server is up and accessible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ecd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(annotator_checkboxes.ui)\n",
    "\n",
    "@interact_manual\n",
    "def corenlp_exploration(\n",
    "    text=cur_text,\n",
    "):\n",
    "    global cur_text, ann, corenlp_annotators, coref_data, parse_data, corenlp_results\n",
    "    if CORENLP_IP:\n",
    "        cur_text = text\n",
    "        ann = None\n",
    "        corenlp_annotators = annotator_checkboxes.selected\n",
    "        with CoreNLPClient(\n",
    "            endpoint=f'http://{CORENLP_IP}:9000',\n",
    "            annotators=corenlp_annotators,\n",
    "            start_server=stanza.server.StartServer.DONT_START,\n",
    "        ) as client:\n",
    "            ann = client.annotate(\n",
    "                text,\n",
    "                properties='english',\n",
    "                output_format='json'\n",
    "            )\n",
    "            corenlp_results = stanza_utils.CoreNLPResults(ann)\n",
    "        print(f'Annotations of \"{text}\":')\n",
    "        @interact(\n",
    "            annotation_type=list(ann.keys())\n",
    "        )\n",
    "        def show_atype(annotation_type):\n",
    "            global coref_data, parse_data\n",
    "            annotation_data = ann[annotation_type]\n",
    "            if isinstance(annotation_data, list):\n",
    "                # List of sentence data...\n",
    "                @interact(\n",
    "                    sentence_num=list(range(len(annotation_data)))\n",
    "                )\n",
    "                def show_sdata(sentence_num):\n",
    "                    global parse_data\n",
    "                    sent_data = annotation_data[sentence_num]\n",
    "                    print(f'Sentence #{sentence_num} (index={sent_data.get(\"index\", sentence_num)})')\n",
    "                    keys = set(sent_data.keys())\n",
    "                    keys.remove('index')\n",
    "                    @interact(\n",
    "                        parse_type=list(keys)\n",
    "                    )\n",
    "                    def show_parse(parse_type):\n",
    "                        global parse_data\n",
    "                        parse_data = sent_data[parse_type]\n",
    "                        if isinstance(parse_data, str):\n",
    "                            print(parse_data)\n",
    "                        else:\n",
    "                            display(pd.DataFrame.from_records(parse_data))\n",
    "            elif isinstance(annotation_data, dict) and len(annotation_data) > 0:\n",
    "                # Dict of coref data...\n",
    "                @interact(\n",
    "                    coref=list(annotation_data.keys())\n",
    "                )\n",
    "                def show_cdata(coref):\n",
    "                    global coref_data\n",
    "                    coref_data = annotation_data[coref]\n",
    "                    display(pd_utils.dicts2df(coref_data, rename={'id': 'word_id'}, item_id=None))\n",
    "    else:\n",
    "        print(f'Please start the CoreNLP server and set the CORENLP_IP variable to interact with this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86e347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa89da5a",
   "metadata": {},
   "source": [
    "## Save current stanza doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40193fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def save_stanza_doc(path=stanza_doc_path):\n",
    "    global stanza_doc_path\n",
    "    stanza_doc_path = path\n",
    "    if path and doc is not None:\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'w', encoding='utf-8') as f:\n",
    "                print(json.dumps(doc.to_dict(), indent=2), file=f)\n",
    "            print(f'Wrote stanza doc to \"{path}\"')\n",
    "        else:\n",
    "            print(f'ERROR: Path \"{path}\" already exists. Not written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd4eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5bf731",
   "metadata": {},
   "source": [
    "## Restore stanza doc from saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0642d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def restore_stanza_doc(path=stanza_doc_path):\n",
    "    global doc, doc_df, stanza_doc_path\n",
    "    stanza_doc_path = path\n",
    "    if path and os.path.exists(path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.loads(f.read())\n",
    "            doc = stanza.models.common.doc.Document(data)\n",
    "            doc_df = stanza_utils.doc2df(doc)\n",
    "            print(f'Stanza document from \"{path}\":')\n",
    "            display(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8f1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "801873a4",
   "metadata": {},
   "source": [
    "## Save current CoreNLP annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def save_corenlp_annotations(path=corenlp_ann_path):\n",
    "    global corenlp_ann_path\n",
    "    corenlp_ann_path = path\n",
    "    if path and ann is not None:\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'w', encoding='utf-8') as f:\n",
    "                print(json.dumps(ann, indent=2), file=f)\n",
    "            print(f'Wrote corenlp annotations to \"{path}\"')\n",
    "        else:\n",
    "            print(f'ERROR: Path \"{path}\" already exists. Not written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa75adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4463b665",
   "metadata": {},
   "source": [
    "## Restore CoreNLP annotations from saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def restore_corenlp_annotations(path=corenlp_ann_path):\n",
    "    global ann, corenlp_results, corenlp_ann_path\n",
    "    corenlp_ann_path = path\n",
    "    if path and os.path.exists(path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            ann = json.loads(f.read())\n",
    "            corenlp_results = stanza_utils.CoreNLPResults(ann)\n",
    "    @interact(\n",
    "        dtype=['dependencies', 'tokens', 'correfs', 'parse']\n",
    "    )\n",
    "    def show_corenlp_results(dtype='dependencies'):\n",
    "        if dtype == 'dependencies':\n",
    "            display(corenlp_results.dependencies_df)\n",
    "        elif dtype == 'tokens':\n",
    "            display(corenlp_results.tokens_df)\n",
    "        elif dtype == 'correfs':\n",
    "            display(corenlp_results.corefs_df)\n",
    "        elif dtype == 'parse':\n",
    "            print(corenlp_results.parse_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51354f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
