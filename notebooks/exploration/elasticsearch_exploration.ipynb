{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ec021c",
   "metadata": {},
   "source": [
    "# Elasticsearch Exploration\n",
    "\n",
    "Explore elasticsearch by indexing and querying WordNet glosses.\n",
    "\n",
    "\n",
    "## Prerequisite Setup: Start Elasticsearch server\n",
    "\n",
    "For convenience, the following will start an elasticsearch server through docker:\n",
    "\n",
    "```sh\n",
    "% bin/start_elasticsearch.sh\n",
    "```\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "Create directories/files with user:group permissions of 1000:1000\n",
    "  * $HOME/data/docker_es\n",
    "     * config -- with configuration files\n",
    "     * data\n",
    "\n",
    "## Data source: Wordnet through NLTK\n",
    "\n",
    "References:\n",
    "\n",
    "* https://www.nltk.org/howto/wordnet.html\n",
    "* https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebooks.util.nbloader\n",
    "import notebooks.nb.utils as nb_utils\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import dataknobs.utils.requests_utils as requests_utils\n",
    "import dataknobs.utils.resource_utils as resource_utils\n",
    "import dataknobs.utils.elasticsearch_utils as es_utils\n",
    "import dataknobs.utils.stanza_utils as stanza_utils\n",
    "import dataknobs.utils.wordnet_utils as wn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a6dce",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83912334",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = resource_utils.active_datadir()\n",
    "\n",
    "##\n",
    "## Derived environmental initializations\n",
    "##\n",
    "## NOTE: Double-check this cell's output in case the auto-derivation fails\n",
    "##       and you will rely on one of these variables.\n",
    "##\n",
    "\n",
    "ELASTICSEARCH_IP = nb_utils.get_subnet_ip('elasticsearch', verbose=True)\n",
    "\n",
    "ES_INDEX = None\n",
    "\n",
    "if ELASTICSEARCH_IP is not None:\n",
    "    ES_INDEX = es_utils.ElasticsearchIndex(\n",
    "        requests_utils.RequestHelper(\n",
    "            ELASTICSEARCH_IP, 9200,\n",
    "        ),\n",
    "        wn_utils.ELASTICSEARCH_TABLE_SETTINGS,\n",
    "    )\n",
    "else:\n",
    "    print(f'***WARNING: ElasticsearchIndex not initialized because elasticsearch server is not up.')\n",
    "\n",
    "    \n",
    "WORDNET_FILEPATH = os.path.join(DATADIR, 'dev/wordnet')\n",
    "\n",
    "\n",
    "##\n",
    "## Global notebook variables\n",
    "##\n",
    "\n",
    "cur_text = ''    # Latest text input\n",
    "batch_filename = 'es_bulk.nltk.sgloss.jsonl'\n",
    "ts_builder = None\n",
    "resp = None\n",
    "cur_query = None\n",
    "cur_syntax = True\n",
    "cur_match_all = False\n",
    "cur_slop = 0\n",
    "cur_gloss_field = 'egloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09c596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dbbdfe9",
   "metadata": {},
   "source": [
    "## Make sure elasticsearch is accessible and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ES_INDEX is not None:\n",
    "    resp = ES_INDEX.get_cluster_health(verbose=True)\n",
    "    if not resp.succeeded:\n",
    "        print(f'FAILED');\n",
    "    else:\n",
    "        print('OK');\n",
    "else:\n",
    "    print(f'No elasticsearch server');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59d1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee00539",
   "metadata": {},
   "source": [
    "## Build a batch file of records for bulk indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5344e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def build_batch(\n",
    "    batch_fname=batch_filename, start_id=0, append=False,\n",
    "    sgloss=True, prev_sgloss_batch='es_bulk.nltk.sgloss.jsonl',\n",
    "):\n",
    "    global batch_filename, ts_builder\n",
    "    batch_filename = batch_fname\n",
    "    if prev_sgloss_batch:\n",
    "        prev_fpath = os.path.join(WORDNET_FILEPATH, prev_sgloss_batch)\n",
    "        ts_builder = wn_utils.build_token_string_builder(prev_fpath)\n",
    "        print(f'NOTE: Loaded ts_builder with sgloss from \"{prev_fpath}\"')\n",
    "    fpath = os.path.join(WORDNET_FILEPATH, batch_filename)\n",
    "    if os.path.exists(fpath) and not append:\n",
    "        print(f'Batch file \"{fpath}\" already exists. Skipping build.')\n",
    "    else:\n",
    "        mode = 'a' if append else 'w'\n",
    "        wn_utils.build_elasticsearch_batch(\n",
    "            fpath, mode=mode, start_id=start_id,\n",
    "            include_sgloss=sgloss,\n",
    "            token_string_builder=ts_builder,\n",
    "        )\n",
    "        print(f'Wrote batch data to: \"{fpath}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c1a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d049c5e7",
   "metadata": {},
   "source": [
    "## Purge existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Run interact to delete currently indexed data')\n",
    "\n",
    "@interact_manual\n",
    "def purge_data():\n",
    "    global resp\n",
    "    if ES_INDEX is None:\n",
    "        print(f'ERROR: Elasticsearch server is not accessible.')\n",
    "    else:\n",
    "        resp = ES_INDEX.inspect_indices(verbose=False)\n",
    "        print(f'({resp.status})\\n{resp.result}')\n",
    "        print(f'\\nRun interact to confirm purging indexed data')\n",
    "\n",
    "        @interact_manual\n",
    "        def do_delete():\n",
    "            resp = ES_INDEX.purge(verbose=True)\n",
    "            if resp.succeeded:\n",
    "                print(f'Deleted data')\n",
    "            else:\n",
    "                print(f'Failed to delete data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52ca59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880783b7",
   "metadata": {},
   "source": [
    "## Bulk load data to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deabbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Run interact to upload data to the index')\n",
    "\n",
    "@interact_manual\n",
    "def upload_data():\n",
    "    global resp\n",
    "    if ES_INDEX is None:\n",
    "        print(f'ERROR: Elasticsearch server is not accessible.')\n",
    "    else:\n",
    "        print(f'Current indices:')\n",
    "        resp = ES_INDEX.inspect_indices(verbose=False)\n",
    "        print(f'({resp.status})\\n{resp.result}')\n",
    "        \n",
    "        print(f'\\nRun interact to bulk load \"{batch_filename}\" to the elasticsearch index')\n",
    "\n",
    "        @interact_manual\n",
    "        def do_upload(verbose=True):\n",
    "            global resp\n",
    "            fpath = os.path.join(WORDNET_FILEPATH, batch_filename)\n",
    "            if os.path.exists(fpath):\n",
    "                # using cell magic:\n",
    "                fpvar = \"@\" + fpath\n",
    "                urlvar = ES_INDEX.request_helper.build_url('_bulk')\n",
    "                if verbose:\n",
    "                    print(f'{datetime.now()}: Uploading \"{fpath}\" to index via \"{urlvar}\"')\n",
    "                upload_output = !curl -s -H \"Content-Type: application/x-ndjson\" -XPOST $urlvar --data-binary $fpvar\n",
    "                if verbose:\n",
    "                    print(f'{datetime.now()}: Done uploading \"{fpath}\" ({len(upload_output[0])})')\n",
    "\n",
    "                # using code (currently BROKEN)\n",
    "                #resp = ES_INDEX.bulk_load(fpath, verbose=verbose)\n",
    "                #print(f'Done uploading (success={resp.succeeded})')\n",
    "\n",
    "                resp = ES_INDEX.inspect_indices(verbose=False)\n",
    "                if verbose:\n",
    "                    print(f'({resp.status})\\n{resp.result}')\n",
    "            else:\n",
    "                print(f'Failed. \"{fpath}\" does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e998f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d297501",
   "metadata": {},
   "source": [
    "## Re-examine table details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Click \"Run Interact\" to re-examine table details:')\n",
    "\n",
    "@interact_manual\n",
    "def reexamine_tables():\n",
    "    resp = ES_INDEX.inspect_indices(verbose=False)\n",
    "    print(f'({resp.status})\\n{resp.result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2dbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8a39c9b",
   "metadata": {},
   "source": [
    "## Lookup word by text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd439664",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def lookup_word_by_text(word_text='', verbose=False):\n",
    "    global resp\n",
    "    if ES_INDEX is None:\n",
    "        print(f'ERROR: Elasticsearch server is not accessible.')\n",
    "    else:\n",
    "        resp = ES_INDEX.search(\n",
    "            es_utils.build_field_query_dict('word', word_text),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        if not resp.succeeded:\n",
    "            print(f'Search request failed:\\n{resp}')\n",
    "        elif not 'hits_df' in resp.extra:\n",
    "            print(f'No results')\n",
    "        else:\n",
    "            display(resp.extra['hits_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fb51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed1f28dd",
   "metadata": {},
   "source": [
    "## Lookup word by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e67acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def lookup_word_by_id(word_id='', verbose=False):\n",
    "    global resp\n",
    "    if ES_INDEX is None:\n",
    "        print(f'ERROR: Elasticsearch server is not accessible.')\n",
    "    else:\n",
    "        resp = ES_INDEX.search(\n",
    "            es_utils.build_field_query_dict('id', word_id),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        if not resp.succeeded:\n",
    "            print(f'Search request failed:\\n{resp}')\n",
    "        elif not 'hits_df' in resp.extra:\n",
    "            print(f'No results')\n",
    "        else:\n",
    "            display(resp.extra['hits_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a9ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96def635",
   "metadata": {},
   "source": [
    "## Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a9fdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    gloss_field=['egloss', 'gloss', 'raw_gloss'],\n",
    ")\n",
    "def search_for_phrase(\n",
    "    phrase=cur_text,\n",
    "    syntax=cur_syntax,\n",
    "    gloss_field=cur_gloss_field,\n",
    "    match_all=cur_match_all,\n",
    "    slop=widgets.IntText(value=cur_slop),\n",
    "    verbose=False\n",
    "):\n",
    "    global resp, cur_query, cur_text, cur_syntax, cur_match_all, cur_slop, ts_builder\n",
    "    cur_text = phrase\n",
    "    cur_syntax = syntax\n",
    "    cur_match_all = match_all\n",
    "    cur_slop = slop\n",
    "    cur_gloss_field = gloss_field\n",
    "    if ES_INDEX is None:\n",
    "        print(f'ERROR: Elasticsearch server is not accessible.')\n",
    "    else:\n",
    "        field = cur_gloss_field\n",
    "        if cur_syntax:\n",
    "            field = 'sgloss'\n",
    "            if ts_builder is None:\n",
    "                ts_builder = stanza_utils.TokenStringBuilder()\n",
    "            phrase = ts_builder.build_string(\n",
    "                phrase,\n",
    "                ignore_utags_override=stanza_utils.DEFAULT_IGNORE_QUERY_UTAGS,\n",
    "            )\n",
    "        if match_all:\n",
    "            cur_query = es_utils.build_phrase_query_dict(\n",
    "                field,\n",
    "                phrase,\n",
    "                slop=cur_slop,\n",
    "            )\n",
    "        else:\n",
    "            cur_query = es_utils.build_field_query_dict(\n",
    "                field, phrase, operator='OR',\n",
    "            )\n",
    "        resp = ES_INDEX.search(\n",
    "            cur_query,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        if not resp.succeeded:\n",
    "            print(f'Search request failed:\\n{resp}')\n",
    "        elif not 'hits_df' in resp.extra:\n",
    "            print(f'No results')\n",
    "        else:\n",
    "            print(f'Results for \"{phrase}\" in \"{field}\":')\n",
    "            display(resp.extra['hits_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d8e8f",
   "metadata": {},
   "source": [
    "## Analyze text (analyzer exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def analyze_text(analyzer='standard', text=''):\n",
    "    global resp\n",
    "    if ES_INDEX is None:\n",
    "        print(f'No elasticsearch index.')\n",
    "    else:\n",
    "        resp = ES_INDEX.analyze(text, analyzer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f24f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_utils.fix_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
